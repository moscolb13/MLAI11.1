{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this dataset, we have a big table where the target variable is the column called \"price\" referring to the price that a specific\n",
    "# car sold for. All the other columns- such as \"region\", \"year\", and \"condition\"- are columns that can be used to evaluate which of these\n",
    "# or combination of these had the greatest impact on the price of the car. \n",
    "\n",
    "# As such, our goal for this exercise is to test the columns, perhaps starting with a correlation matrix, to zoom in into certain columns. Depending \n",
    "# on the number of columns, we can then test a variety of models, such as a linear regression or a random forest, to see how well\n",
    "# the models correpond to the data. \n",
    "# The goal would be find an appropiate model, improve upon it, then based on the model be able to discern which factors affected the price\n",
    "# of the car the most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first thing we need to do is get acquainted with the data. To do this, we can run a few functions:\n",
    "# data.head() to see what the top 5 rows look like\n",
    "# data.info() to see how many rows total and the name and object types of the columns\n",
    "# isnull.sum() to figure out how many empty rows we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data = pd.read_csv(r'C:\\Users\\mosco\\Downloads\\practical_application_II_starter2\\data\\vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 id                  region  price    year manufacturer  \\\n",
       "0       7222695916                prescott   6000     NaN          NaN   \n",
       "1       7218891961            fayetteville  11900     NaN          NaN   \n",
       "2       7221797935            florida keys  21000     NaN          NaN   \n",
       "3       7222270760  worcester / central MA   1500     NaN          NaN   \n",
       "4       7210384030              greensboro   4900     NaN          NaN   \n",
       "...            ...                     ...    ...     ...          ...   \n",
       "426875  7301591192                 wyoming  23590  2019.0       nissan   \n",
       "426876  7301591187                 wyoming  30590  2020.0        volvo   \n",
       "426877  7301591147                 wyoming  34990  2020.0     cadillac   \n",
       "426878  7301591140                 wyoming  28990  2018.0        lexus   \n",
       "426879  7301591129                 wyoming  30590  2019.0          bmw   \n",
       "\n",
       "                           model condition    cylinders    fuel  odometer  \\\n",
       "0                            NaN       NaN          NaN     NaN       NaN   \n",
       "1                            NaN       NaN          NaN     NaN       NaN   \n",
       "2                            NaN       NaN          NaN     NaN       NaN   \n",
       "3                            NaN       NaN          NaN     NaN       NaN   \n",
       "4                            NaN       NaN          NaN     NaN       NaN   \n",
       "...                          ...       ...          ...     ...       ...   \n",
       "426875         maxima s sedan 4d      good  6 cylinders     gas   32226.0   \n",
       "426876  s60 t5 momentum sedan 4d      good          NaN     gas   12029.0   \n",
       "426877          xt4 sport suv 4d      good          NaN  diesel    4174.0   \n",
       "426878           es 350 sedan 4d      good  6 cylinders     gas   30112.0   \n",
       "426879  4 series 430i gran coupe      good          NaN     gas   22716.0   \n",
       "\n",
       "       title_status transmission                VIN drive size       type  \\\n",
       "0               NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "1               NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "2               NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "3               NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "4               NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "...             ...          ...                ...   ...  ...        ...   \n",
       "426875        clean        other  1N4AA6AV6KC367801   fwd  NaN      sedan   \n",
       "426876        clean        other  7JR102FKXLG042696   fwd  NaN      sedan   \n",
       "426877        clean        other  1GYFZFR46LF088296   NaN  NaN  hatchback   \n",
       "426878        clean        other  58ABK1GG4JU103853   fwd  NaN      sedan   \n",
       "426879        clean        other  WBA4J1C58KBM14708   rwd  NaN      coupe   \n",
       "\n",
       "       paint_color state  \n",
       "0              NaN    az  \n",
       "1              NaN    ar  \n",
       "2              NaN    fl  \n",
       "3              NaN    ma  \n",
       "4              NaN    nc  \n",
       "...            ...   ...  \n",
       "426875         NaN    wy  \n",
       "426876         red    wy  \n",
       "426877       white    wy  \n",
       "426878      silver    wy  \n",
       "426879         NaN    wy  \n",
       "\n",
       "[426880 rows x 18 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.head # shows us a preview of the top of the dataset. Lots of NaNs in these first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  int64  \n",
      " 1   region        426880 non-null  object \n",
      " 2   price         426880 non-null  int64  \n",
      " 3   year          425675 non-null  float64\n",
      " 4   manufacturer  409234 non-null  object \n",
      " 5   model         421603 non-null  object \n",
      " 6   condition     252776 non-null  object \n",
      " 7   cylinders     249202 non-null  object \n",
      " 8   fuel          423867 non-null  object \n",
      " 9   odometer      422480 non-null  float64\n",
      " 10  title_status  418638 non-null  object \n",
      " 11  transmission  424324 non-null  object \n",
      " 12  VIN           265838 non-null  object \n",
      " 13  drive         296313 non-null  object \n",
      " 14  size          120519 non-null  object \n",
      " 15  type          334022 non-null  object \n",
      " 16  paint_color   296677 non-null  object \n",
      " 17  state         426880 non-null  object \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 58.6+ MB\n"
     ]
    }
   ],
   "source": [
    "car_data.info()  #shows us we are deadling with 18 columns total, and that the total number of rows if ~426k. We can also see some columns\n",
    "# aren't missing any info at all, like \"id\", \"region\", and \"price\", whereas some other columns like \"size\" have a lot of empty values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "price                0\n",
       "state                0\n",
       "region               0\n",
       "year              1205\n",
       "transmission      2556\n",
       "fuel              3013\n",
       "odometer          4400\n",
       "model             5277\n",
       "title_status      8242\n",
       "manufacturer     17646\n",
       "type             92858\n",
       "paint_color     130203\n",
       "drive           130567\n",
       "VIN             161042\n",
       "condition       174104\n",
       "cylinders       177678\n",
       "size            306361\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.isnull().sum().sort_values()  # tells us how many missing values we have per column. \"Size\" is the worst offender, but several others like \"condition\",\n",
    "# \"cylinders\", \"VIN\", \"drive\", and \"paint_color\" are also pretty significant, missing approximately ~30% of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426880, 18)\n",
      "(426880, 12)\n"
     ]
    }
   ],
   "source": [
    "# Since our initial overview shows that some fields are missing a ton of data, I have decided to drop any column that is missing at least 30%\n",
    "# of data. I'm choosing 30% based on how many of the fields (cylinders, condition, drive) are missing around that threshold.\n",
    "\n",
    "threshold = len(car_data) * 0.7  #threshold keep any column in which at least 70% of the data is NON null. Drop everything else.\n",
    "car_data_cleaned = car_data.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "print(car_data.shape)\n",
    "print(car_data_cleaned.shape) #the 70% non-null threshold dropped 6 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341386</th>\n",
       "      <td>7307232766</td>\n",
       "      <td>york</td>\n",
       "      <td>42990</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genesis G70 3.3T Sedan 4D</td>\n",
       "      <td>other</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>sedan</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136019</th>\n",
       "      <td>7316740008</td>\n",
       "      <td>spokane / coeur d'alene</td>\n",
       "      <td>2395</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT Cruiser Limited</td>\n",
       "      <td>gas</td>\n",
       "      <td>127506.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>wagon</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>7302437530</td>\n",
       "      <td>huntsville / decatur</td>\n",
       "      <td>4500</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>cadillac</td>\n",
       "      <td>dts</td>\n",
       "      <td>gas</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>sedan</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70546</th>\n",
       "      <td>7313661438</td>\n",
       "      <td>yuba-sutter</td>\n",
       "      <td>10988</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>kia</td>\n",
       "      <td>sorento lx - awd - rear camera - bluetooth -</td>\n",
       "      <td>gas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300617</th>\n",
       "      <td>7303667811</td>\n",
       "      <td>mansfield</td>\n",
       "      <td>19990</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>mitsubishi</td>\n",
       "      <td>outlander sport es</td>\n",
       "      <td>other</td>\n",
       "      <td>11103.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>oh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                   region  price    year manufacturer  \\\n",
       "341386  7307232766                     york  42990  2020.0          NaN   \n",
       "136019  7316740008  spokane / coeur d'alene   2395  2002.0          NaN   \n",
       "3742    7302437530     huntsville / decatur   4500  2006.0     cadillac   \n",
       "70546   7313661438              yuba-sutter  10988  2014.0          kia   \n",
       "300617  7303667811                mansfield  19990  2020.0   mitsubishi   \n",
       "\n",
       "                                               model   fuel  odometer  \\\n",
       "341386                     Genesis G70 3.3T Sedan 4D  other    2760.0   \n",
       "136019                            PT Cruiser Limited    gas  127506.0   \n",
       "3742                                             dts    gas  100000.0   \n",
       "70546   sorento lx - awd - rear camera - bluetooth -    gas       NaN   \n",
       "300617                            outlander sport es  other   11103.0   \n",
       "\n",
       "       title_status transmission       type state  \n",
       "341386        clean        other      sedan    pa  \n",
       "136019        clean    automatic      wagon    id  \n",
       "3742          clean    automatic      sedan    al  \n",
       "70546         clean    automatic        SUV    ca  \n",
       "300617        clean        other  hatchback    oh  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what our new dataframe looks like:\n",
    "\n",
    "car_data_cleaned.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  int64  \n",
      " 1   region        426880 non-null  object \n",
      " 2   price         426880 non-null  int64  \n",
      " 3   year          425675 non-null  float64\n",
      " 4   manufacturer  409234 non-null  object \n",
      " 5   model         421603 non-null  object \n",
      " 6   fuel          423867 non-null  object \n",
      " 7   odometer      422480 non-null  float64\n",
      " 8   title_status  418638 non-null  object \n",
      " 9   transmission  424324 non-null  object \n",
      " 10  type          334022 non-null  object \n",
      " 11  state         426880 non-null  object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 39.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# now we run into another issue which is object type. Let's run .info() on this new cleaned data set to see what we are dealing with:\n",
    "\n",
    "car_data_cleaned.info()  #we see that we have some columns that are floats but quite a few columns that are string objects. one thing i like to do is\n",
    "#count the number of unique values in each column to see how easy/crazy it may be to categorize them/bucket them/one-hot-encode them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transmission         3\n",
       "fuel                 5\n",
       "title_status         6\n",
       "type                13\n",
       "manufacturer        42\n",
       "state               51\n",
       "year               114\n",
       "region             404\n",
       "price            15655\n",
       "model            29649\n",
       "odometer        104870\n",
       "id              426880\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data_cleaned.nunique().sort_values()\n",
    "\n",
    "#we see that for \"transmission\" even though its a string object, theres just 3 distinct values within it. \"fuel\" has only 5, \"title_status\" only 6. \n",
    "# lets count only categorical ones to see what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model           29649\n",
       "region            404\n",
       "state              51\n",
       "manufacturer       42\n",
       "type               13\n",
       "title_status        6\n",
       "fuel                5\n",
       "transmission        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data_cleaned.select_dtypes(include='object').nunique().sort_values(ascending=False)\n",
    "\n",
    "# ok, counting categorial columns, we see that the highest is model, with 29k unique values, followed by a sharp drop to \"region\" with 404 unique \n",
    "# values, and then down from there. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>odometer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.268800e+05</td>\n",
       "      <td>4.268800e+05</td>\n",
       "      <td>425675.000000</td>\n",
       "      <td>4.224800e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.311487e+09</td>\n",
       "      <td>7.519903e+04</td>\n",
       "      <td>2011.235191</td>\n",
       "      <td>9.804333e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.473170e+06</td>\n",
       "      <td>1.218228e+07</td>\n",
       "      <td>9.452120</td>\n",
       "      <td>2.138815e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.207408e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.308143e+09</td>\n",
       "      <td>5.900000e+03</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>3.770400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.312621e+09</td>\n",
       "      <td>1.395000e+04</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>8.554800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.315254e+09</td>\n",
       "      <td>2.648575e+04</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1.335425e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.317101e+09</td>\n",
       "      <td>3.736929e+09</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price           year      odometer\n",
       "count  4.268800e+05  4.268800e+05  425675.000000  4.224800e+05\n",
       "mean   7.311487e+09  7.519903e+04    2011.235191  9.804333e+04\n",
       "std    4.473170e+06  1.218228e+07       9.452120  2.138815e+05\n",
       "min    7.207408e+09  0.000000e+00    1900.000000  0.000000e+00\n",
       "25%    7.308143e+09  5.900000e+03    2008.000000  3.770400e+04\n",
       "50%    7.312621e+09  1.395000e+04    2013.000000  8.554800e+04\n",
       "75%    7.315254e+09  2.648575e+04    2017.000000  1.335425e+05\n",
       "max    7.317101e+09  3.736929e+09    2022.000000  1.000000e+07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have a better idea of what the dataset looks like lets use the .describe() menthod to see how far the numbers are from each other\n",
    "\n",
    "car_data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one easy thing to clean this dataset is to set the index to ID, so we dont have redundant columns. \n",
    "\n",
    "car_data_cleaned.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7312598567</th>\n",
       "      <td>boise</td>\n",
       "      <td>17995</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>a6</td>\n",
       "      <td>gas</td>\n",
       "      <td>59331.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>sedan</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314348692</th>\n",
       "      <td>ft myers / SW florida</td>\n",
       "      <td>18000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>volvo</td>\n",
       "      <td>xc60 t5 drive-e premier</td>\n",
       "      <td>gas</td>\n",
       "      <td>42723.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314095002</th>\n",
       "      <td>greensboro</td>\n",
       "      <td>38896</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>f250 super duty lariat</td>\n",
       "      <td>diesel</td>\n",
       "      <td>141590.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307219659</th>\n",
       "      <td>indianapolis</td>\n",
       "      <td>3981</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>dodge</td>\n",
       "      <td>grand caravan se</td>\n",
       "      <td>gas</td>\n",
       "      <td>149878.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>mini-van</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309028645</th>\n",
       "      <td>western slope</td>\n",
       "      <td>5500</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>jeep</td>\n",
       "      <td>commander 4wd</td>\n",
       "      <td>gas</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           region  price    year manufacturer  \\\n",
       "id                                                              \n",
       "7312598567                  boise  17995  2013.0         audi   \n",
       "7314348692  ft myers / SW florida  18000  2016.0        volvo   \n",
       "7314095002             greensboro  38896  2012.0         ford   \n",
       "7307219659           indianapolis   3981  2005.0        dodge   \n",
       "7309028645          western slope   5500  2007.0         jeep   \n",
       "\n",
       "                              model    fuel  odometer title_status  \\\n",
       "id                                                                   \n",
       "7312598567                       a6     gas   59331.0        clean   \n",
       "7314348692  xc60 t5 drive-e premier     gas   42723.0        clean   \n",
       "7314095002   f250 super duty lariat  diesel  141590.0        clean   \n",
       "7307219659         grand caravan se     gas  149878.0        clean   \n",
       "7309028645            commander 4wd     gas  197000.0        clean   \n",
       "\n",
       "           transmission      type state  \n",
       "id                                       \n",
       "7312598567    automatic     sedan    id  \n",
       "7314348692    automatic       SUV    fl  \n",
       "7314095002    automatic       NaN    nc  \n",
       "7307219659    automatic  mini-van    in  \n",
       "7309028645    automatic       SUV    co  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data_cleaned.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>odometer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7315205447</th>\n",
       "      <td>45950</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>143909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316973857</th>\n",
       "      <td>11000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>120700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314048278</th>\n",
       "      <td>14000</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>74890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302106754</th>\n",
       "      <td>15977</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>76003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315858612</th>\n",
       "      <td>24590</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>17221.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price    year  odometer\n",
       "id                                 \n",
       "7315205447  45950  2014.0  143909.0\n",
       "7316973857  11000  2005.0  120700.0\n",
       "7314048278  14000  2018.0   74890.0\n",
       "7302106754  15977  2015.0   76003.0\n",
       "7315858612  24590  2019.0   17221.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the number of disctinct values for each filed above, \"state\" has too many at 51. Decided to keep only\n",
    "# the object fields that have few distinct values: \"type, \"title_statis\", \"fuel\", \"transmission\". In addition ill also keep all the numerical columns. \n",
    "# this leads me to a final claned dataset:\n",
    "\n",
    "car_final = car_data_cleaned[['price','year','odometer']]\n",
    "car_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_final = car_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gonna run both a linear regression and a random forest model. I will split the data into 60/20/20\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = car_final.drop(columns='price')\n",
    "y = car_final['price']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'madison'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18152\\3056921842.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Linear Regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_val_pred_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Random Forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    649\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         )\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m         raise ValueError(\n\u001b[0;32m   1103\u001b[0m             \u001b[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    876\u001b[0m                         )\n\u001b[0;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m                 raise ValueError(\n\u001b[0;32m    882\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mxp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"numpy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"numpy.array_api\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         if (\n\u001b[0;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'madison'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_val_pred_lr = lr.predict(X_val)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_val_pred_rf = rf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6974, 84269]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m evaluate(y_val, y_val_pred_lr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m evaluate(y_val, y_val_pred_rf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[51], line 4\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(y_true, y_pred, model_name)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(y_true, y_pred, model_name):\n\u001b[1;32m----> 4\u001b[0m     mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_true, y_pred)\n\u001b[0;32m      5\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_true, y_pred)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:196\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_absolute_error\u001b[39m(\n\u001b[0;32m    142\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m ):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    197\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    200\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6974, 84269]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"{model_name} MAE: {mae:,.2f}\")\n",
    "    print(f\"{model_name} MSE: {mse:,.2f}\")\n",
    "    print('-' * 30)\n",
    "\n",
    "evaluate(y_val, y_val_pred_lr, \"Linear Regression\")\n",
    "evaluate(y_val, y_val_pred_rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this project, I cleaned and prepared a dataset of used vehicle listings to explore which features influence car prices. \n",
    "#I removed columns with heavy missingness, filtered out unknown entries, and selected a set of relevant numeric and \n",
    "#categorical features (year, odometer, fuel, title_status, type, and transmission). After one-hot encoding, I built and evaluated \n",
    "#two models  linear regression and random forest  using a 60/20/20 train/validation/test split.\n",
    "\n",
    "#Both models returned high error values (MAE ~ $150170K). If I continued, I would focus on removing or capping those outliers and \n",
    "#tuning the model parameters. Despite the rough metrics, this was a solid first pass at the modeling pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
